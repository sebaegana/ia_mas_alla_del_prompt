---
listing_title: "Diapositiva 01"
title: "IA m√°s all√° del prompt"
subtitle: "RAG, automatizaci√≥n y memoria"
institution: "UNegocios"
lang: es
date: today
format:
  revealjs:
    theme: simple
    slide-number: true
    self-contained: true
    incremental: true
    transition: slide
    logo: "imagenes/Imagen1.jpg"
    footer: "¬© Sebasti√°n Ega√±a Santib√°√±ez"
    include-in-header: styles.html
  pdf:
    toc: false
    papersize: a4
    geometry: margin=1in
---

```{r load_packages, message=FALSE, warning=FALSE, include=FALSE}
library(fontawesome)
library(knitr)
library(tidyverse)
library(kableExtra)
```
---

# Enlaces

-   `r fa("message", fill = "steelblue")`segana\@fen.uchile.cl
-   `r fa("computer", fill = "steelblue")` <https://segana.netlify.app>
-   `r fa("linkedin", fill = "steelblue")` <https://www.linkedin.com/in/sebastian-egana-santibanez/> 
- `r fa("github", fill = "steelblue")` <https://github.com/sebaegana>

---

# ¬øPor qu√© ir m√°s all√°?

Cuando ya debemos pasar de la interacci√≥n un poco m√°s simple e intentar estabilizar lo que obtenemos desde los LLM's.

---

# Mensaje central

- Para que los LLM generen valor real en organizaciones, debemos estabilizar sus salidas mediante contexto controlado, flujos reproducibles y persistencia de conocimiento.

---

## El problema: la inestabilidad de los LLM

Los LLM's son probabil√≠sticos, no deterministas.

El mismo prompt ‚Üí resultados distintos

::::columns

:::column

Sensibles a:

<ul style="list-style-type:none; padding-left:0;">
<li> Orden del texto  </li>
<li> Contexto previo  </li>
<li>Temperatura  </li>
<li>Estado de la conversaci√≥n  </li>
</ul>

::: 

:::column
¬øQue implica esto?

<ul style="list-style-type:none; padding-left:0;">
<li>Buen desempe√±o en demos  </li>
<li> ‚ùå Fr√°giles en producci√≥n  </li>
<li> ‚ùå Dif√≠ciles de auditar  </li>
<li>‚ùå Resultados no reproducibles  </li>
</ul>

::: 
::::

---

## ¬øPor qu√© el prompt no escala?

**Aqu√≠ ocurre el quiebre conceptual**

:::tiny
El prompt:

<ul style="list-style-type:none; padding-left:0;">
<li> Vive en la cabeza del usuario </li> 
<li> No es versionable  </li>
<li> No es auditable  </li>
<li> No es reproducible</li>
</ul>

:::

üìå **Analog√≠a potente**

> Usar solo prompts es como entrenar un modelo ‚Äúde memoria‚Äù cada vez.

---

## Objetivo real: estabilizar la salida del modelo

::::columns

:::column

No buscamos:

<ul style="list-style-type:none; padding-left:0;">
<li> ‚Äúrespuestas creativas‚Äù</li>
</ul>

:::

:::column

Buscamos:

<ul style="list-style-type:none; padding-left:0;">
<li> consistencia</li>
<li> trazabilidad</li>
<li> control</li>
<li> alineamiento con negocio</li>
</ul>

:::

üìå **Cambio de foco**

> LLM como componente, no como or√°culo

:::

---

## Primer pilar: RAG (Retrieval-Augmented Generation)

::::columns

:::column

**Qu√© problema resuelve**

<ul style="list-style-type:none; padding-left:0;">
<li> Alucinaciones</li>
<li> Conocimiento obsoleto</li>
<li> Dependencia del prompt</li>
</ul>

:::

:::column

**Qu√© hace RAG**

Separa:

<ul style="list-style-type:none; padding-left:0;">
<li> conocimiento (documentos)</li>
<li> razonamiento (modelo)</li>
</ul>

:::
::::

üìå **El RAG no inventa, recupera**

> RAG transforma un LLM gen√©rico en un sistema experto contextual.

---

## En detalle

![Recuperada en: https://mindfulmatrix.substack.com/p/build-a-simple-llm-application-with?utm_source=chatgpt.com](imagenes/rag_01.jpg)

---

## Segundo pilar: Automatizaci√≥n (orquestaci√≥n)

::::columns

:::column

Problema:

<ul style="list-style-type:none; padding-left:0;">
<li> Uso manual</li>
<li> Resultados no repetibles</li>
<li> Dependencia humana</li>
</ul>

:::

:::column

Automatizar implica

<ul style="list-style-type:none; padding-left:0;">
<li> Flujos definidos</li>
<li> Entradas controladas</li>
<li> Salidas esperadas</li>
<li> Evaluaci√≥n autom√°tica</li>
</ul>

:::

::::

---

## üíª Ejemplo de un flujo

![Ejemplo generado dentro del curso](imagenes/n8n_example.png)

---

## ü§Ø ¬øD√≥nde entra el LLM?

::::columns

:::column

:::tinier

**System Instructions**

Role: You are a highly intelligent and accurate sentiment analyzer.

Task: Analyze the sentiment of the provided text and categorize it into one of the following classes:

<ul style="list-style-type:none; padding-left:0;">
<li>Positive</li>
<li>Neutral</li>
<li>Negative</li>
</ul>

**Output Rules**

<ul style="list-style-type:none; padding-left:0;">
<li>Output only JSON</li>
<li>Follow the provided formatting instructions strictly</li>
<li>Do not include any additional text outside the JSON</li>
</ul>

**Output Format Constraint**

**JSON Schema Compliance**
<ul style="list-style-type:none; padding-left:0;">
<li>The output must conform exactly to a given JSON Schema instance.</li>
<li>All required fields must be present. </li>
<li>No extra fields are allowed. </li>
<li>No trailing commas.</li>
</ul>
:::

:::

:::column

:::tinier
Schema:
:::

:::tiny

```

{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "properties": {
    "sentiment": {
      "type": "string",
      "enum": ["Positive", "Neutral", "Negative"]
    },
    "strength": {
      "type": "number",
      "minimum": 0,
      "maximum": 1,
      "description": "Strength score for sentiment in relation to the category"
    },
    "confidence": {
      "type": "number",
      "minimum": 0,
      "maximum": 1
    }
  },
  "required": ["sentiment", "strength", "confidence"],
  "additionalProperties": false
}

```
:::

:::

::::

---

## üìå **Frase clave:**

> Sin automatizaci√≥n, la IA es solo una herramienta; con automatizaci√≥n, es un sistema.

El paso posterior a esto es la construcci√≥n de agentes en donde el LLM opera como un orquestador de distintas herramnientas, que pueden ser tan simple como una calculadora o m√°s compleja como otro LLM, entre otras.

---


## Tercer pilar: Memoria (estado y aprendizaje)

:::tiny

::::columns

:::column

**Qu√© NO es memoria**

<ul style="list-style-type:none; padding-left:0;">
<li>Historial infinito del chat ‚ùå </li>
</ul>

**Qu√© S√ç es memoria**

<ul style="list-style-type:none; padding-left:0;">
<li>Persistencia selectiva </li>
<li>Estado del proceso </li>
<li>Preferencias </li>
<li>Decisiones pasadas </li>
</ul>

:::

:::column

**Tipos**

<ul style="list-style-type:none; padding-left:0;">
<li>üü¢ Memoria de corto plazo (ventana de contexto): se mantiene dentro de la covnersaci√≥n  y est√° limitada por tokens </li>
<li>üîµ Memoria de largo plazo (vectores / DB): permite "recuerdar" en el largo plazo y habilita la posibilidad de personalizar al modificarla </li>
<li>üü† Memoria operacional (estado del flujo): relacionada con agentes y orientada a determinar los pasos del proceso y el estado en el que se encuentra </li>
</ul>
:::

::::

:::

---

## La integraci√≥n: Prompt + RAG + Automatizaci√≥n + Memoria

:::tiny

Aqu√≠ est√° la tesis completa

<ul style="list-style-type:none; padding-left:0;">
<li>Componente	Rol</li>
<li>Prompt	Interfaz humana</li>
<li>RAG	Contexto confiable</li>
<li>Automatizaci√≥n	Repetibilidad</li>
<li>Memoria	Continuidad</li>
</ul>

**üéØ Mensaje central:**

> La estabilidad no viene del prompt, sino del sistema.

:::

---

## Implicancias para organizaciones

üõ¨ **Aterrizaje ejecutivo**

<ul style="list-style-type:none; padding-left:0;">
<li>Menos riesgo</li>
<li>Menos alucinaciones</li>
<li>M√°s confianza</li>
<li>Escalabilidad real</li>
<li>Auditor√≠a y control</li>
</ul>

üìå **Cambio de mentalidad:**

> No implementar IA ‚Üí dise√±ar sistemas con IA.

---

## Cierre 

> El futuro de la IA no es escribir mejores prompts, es dise√±ar mejores sistemas.

---

# Referencias

:::tiny

Gandhi, S. (2024, April 7). Building LLM application using RAG: How to query your document using LLM. Mindful Matrix. Retrieved from <https://mindfulmatrix.substack.com/p/build-a-simple-llm-application-with>

:::
